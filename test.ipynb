{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## THIS NOTEBOOK IS FOR BEING FAMILIAR WITH DEEP LEARNING\n",
    "- We will use tensorflow and keras for training\n",
    "- We will have a small, custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-13 00:10:20.314968: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-13 00:10:20.363521: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-13 00:10:21.208312: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Embedding, Bidirectional, LSTM, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data\n",
    "sentences = [\n",
    "    (\"hello world\", \"hi world\"),\n",
    "    (\"apple orange\", \"apple banana\"),\n",
    "    (\"machine learning\", \"deep learning\"),\n",
    "    (\"openai\", \"openai gpt\"),\n",
    "    # Add more data here\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello world hi world hello world', 'apple orange apple banana apple orange', 'machine learning deep learning machine learning', 'openai openai gpt openai']\n"
     ]
    }
   ],
   "source": [
    "# Combine sentences to form corrupted input\n",
    "corrupted_sentences = [s1 + ' ' + s2 + ' ' + s1 for s1, s2 in sentences]\n",
    "labels = [s2 for s1, s2 in sentences]\n",
    "print(corrupted_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 18\n"
     ]
    }
   ],
   "source": [
    "# Define tokenizer and fit on corrupted sentences\n",
    "tokenizer = Tokenizer(char_level=True)\n",
    "tokenizer.fit_on_texts(corrupted_sentences)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print('Vocabulary Size: %d' % vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing and add padding\n",
    "\n",
    "# Input data\n",
    "max_length = max([len(s) for s in corrupted_sentences])\n",
    "X = tokenizer.texts_to_sequences(corrupted_sentences)\n",
    "X = pad_sequences(X, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape:  (4, 47)\n",
      "Y shape:  (4, 47)\n"
     ]
    }
   ],
   "source": [
    "# Labels\n",
    "# Do the same for the labels\n",
    "Y = tokenizer.texts_to_sequences(labels)\n",
    "Y = pad_sequences(Y, maxlen=max_length, padding='post')\n",
    "\n",
    "print(\"X shape: \", X.shape)\n",
    "print(\"Y shape: \", Y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_11 (InputLayer)       [(None, 47)]              0         \n",
      "                                                                 \n",
      " embedding_10 (Embedding)    (None, 47, 64)            1152      \n",
      "                                                                 \n",
      " bidirectional_10 (Bidirect  (None, 64)                24832     \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 18)                1170      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27154 (106.07 KB)\n",
      "Trainable params: 27154 (106.07 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/tam/tam-code/string-matching-rnn/venv/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1338, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/tam/tam-code/string-matching-rnn/venv/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1322, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/tam/tam-code/string-matching-rnn/venv/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1303, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/tam/tam-code/string-matching-rnn/venv/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1081, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/home/tam/tam-code/string-matching-rnn/venv/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1139, in compute_loss\n        return self.compiled_loss(\n    File \"/home/tam/tam-code/string-matching-rnn/venv/lib/python3.10/site-packages/keras/src/engine/compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/home/tam/tam-code/string-matching-rnn/venv/lib/python3.10/site-packages/keras/src/losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/home/tam/tam-code/string-matching-rnn/venv/lib/python3.10/site-packages/keras/src/losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/home/tam/tam-code/string-matching-rnn/venv/lib/python3.10/site-packages/keras/src/losses.py\", line 2122, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/home/tam/tam-code/string-matching-rnn/venv/lib/python3.10/site-packages/keras/src/backend.py\", line 5560, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (4, 47) and (4, 18) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 13\u001b[0m\n\u001b[1;32m      9\u001b[0m autoencoder\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m, loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcategorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[39mprint\u001b[39m(autoencoder\u001b[39m.\u001b[39msummary())\n\u001b[0;32m---> 13\u001b[0m autoencoder\u001b[39m.\u001b[39;49mfit(X, Y, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m4\u001b[39;49m)\n",
      "File \u001b[0;32m~/tam-code/string-matching-rnn/venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_file_3xjk6d2.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/tam/tam-code/string-matching-rnn/venv/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1338, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/tam/tam-code/string-matching-rnn/venv/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1322, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/tam/tam-code/string-matching-rnn/venv/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1303, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/tam/tam-code/string-matching-rnn/venv/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1081, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/home/tam/tam-code/string-matching-rnn/venv/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1139, in compute_loss\n        return self.compiled_loss(\n    File \"/home/tam/tam-code/string-matching-rnn/venv/lib/python3.10/site-packages/keras/src/engine/compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/home/tam/tam-code/string-matching-rnn/venv/lib/python3.10/site-packages/keras/src/losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/home/tam/tam-code/string-matching-rnn/venv/lib/python3.10/site-packages/keras/src/losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/home/tam/tam-code/string-matching-rnn/venv/lib/python3.10/site-packages/keras/src/losses.py\", line 2122, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/home/tam/tam-code/string-matching-rnn/venv/lib/python3.10/site-packages/keras/src/backend.py\", line 5560, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (4, 47) and (4, 18) are incompatible\n"
     ]
    }
   ],
   "source": [
    "# Build the autoencoder model (same as before)\n",
    "input_layer = Input(shape=(max_length,))\n",
    "embedding = Embedding(vocab_size, 64, input_length=max_length)(input_layer)\n",
    "bi_lstm = Bidirectional(LSTM(32))(embedding)\n",
    "decoded = Dense(vocab_size, activation='softmax')(bi_lstm)\n",
    "\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoded)\n",
    "# autoencoder.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "autoencoder.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "print(autoencoder.summary())\n",
    "\n",
    "\n",
    "autoencoder.fit(X, Y, epochs=10, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 637ms/step\n",
      "1/1 [==============================] - 1s 637ms/step\n"
     ]
    }
   ],
   "source": [
    "# Encode the sentences\n",
    "encoder = Model(inputs=input_layer, outputs=bi_lstm)\n",
    "encoded_data = encoder.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now you can use the encoded_data for prediction\n",
    "new_samples = [\n",
    "    (\"hello world\", \"hi there\"),\n",
    "    (\"apple banana\", \"banana apple\"),\n",
    "    (\"machine learning\", \"learning machine\"),\n",
    "    (\"openai\", \"gpt openai\"),\n",
    "    # Add more new samples here\n",
    "]\n",
    "\n",
    "new_encoded_samples = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Encoded data for new samples:\n",
      "[array([[-0.01078334, -0.01630737,  0.02797763, -0.00336495, -0.01090707,\n",
      "        -0.02515487,  0.02766134, -0.01381304,  0.01710702, -0.02640632,\n",
      "        -0.0233629 , -0.00292518, -0.0191737 ,  0.01790585,  0.02886255,\n",
      "        -0.00611169,  0.03289169, -0.01349095, -0.01487449, -0.02337017,\n",
      "         0.02534136, -0.00255498,  0.01700653, -0.00702298,  0.00211998,\n",
      "         0.02680595,  0.0008493 ,  0.00223542, -0.02161465,  0.02137545,\n",
      "        -0.0032118 , -0.02374905,  0.01421249,  0.00284617,  0.00553894,\n",
      "        -0.00778293, -0.00454393, -0.00229641,  0.0053709 ,  0.00148447,\n",
      "        -0.00575233,  0.00627638,  0.00236789, -0.00053764, -0.00858179,\n",
      "         0.00280549,  0.00697564, -0.0032546 ,  0.00166743,  0.0016205 ,\n",
      "        -0.0065305 ,  0.00274602, -0.01002082,  0.00664434,  0.0036468 ,\n",
      "        -0.00441237, -0.00139709,  0.00259375, -0.01472466,  0.00917792,\n",
      "        -0.00579543, -0.0083159 ,  0.00594948,  0.01332669]],\n",
      "      dtype=float32), array([[-9.29962005e-03, -1.40536698e-02,  2.68905926e-02,\n",
      "        -1.73024461e-03, -1.10858986e-02, -2.40727570e-02,\n",
      "         2.61927582e-02, -1.39328083e-02,  1.67446733e-02,\n",
      "        -2.16868073e-02, -2.15372257e-02,  1.00411307e-04,\n",
      "        -1.66733842e-02,  1.96521357e-02,  2.82820705e-02,\n",
      "        -6.77045062e-03,  2.89581940e-02, -1.37278233e-02,\n",
      "        -1.46393683e-02, -2.56598834e-02,  2.65422631e-02,\n",
      "         3.54171389e-05,  1.68718453e-02, -5.89979580e-03,\n",
      "         1.66837533e-04,  2.82666590e-02,  1.32319203e-03,\n",
      "         3.14023183e-03, -2.06443612e-02,  2.22180020e-02,\n",
      "        -3.71643645e-03, -2.02950761e-02,  1.50336069e-03,\n",
      "        -1.52481226e-02,  2.69146713e-05, -4.87951143e-03,\n",
      "        -6.36938680e-03,  9.72010102e-03,  2.13676468e-02,\n",
      "         1.60746574e-02, -1.12060979e-02,  3.35993022e-02,\n",
      "         7.89071433e-04, -1.10404715e-02,  4.01321566e-03,\n",
      "         8.33784789e-03,  5.29572414e-03,  2.41541397e-03,\n",
      "         8.80540349e-03, -6.19610131e-04, -1.24734845e-02,\n",
      "        -3.56937200e-03,  1.28210336e-03,  1.99186001e-02,\n",
      "        -1.52203478e-02, -1.64074004e-02, -6.77140942e-03,\n",
      "        -2.01598890e-02,  8.19935463e-04, -5.94144315e-03,\n",
      "         1.81469414e-03,  9.82143544e-03,  1.87426396e-02,\n",
      "        -5.86642942e-04]], dtype=float32), array([[-0.00483991,  0.02707596, -0.00535996, -0.01245845,  0.0021523 ,\n",
      "        -0.01276314, -0.00561677,  0.00806835, -0.00528189,  0.0132658 ,\n",
      "         0.00804854,  0.0139221 , -0.00931999,  0.00725843,  0.00184874,\n",
      "        -0.00890393,  0.0034226 , -0.00273854, -0.03876424,  0.01440076,\n",
      "        -0.00570397,  0.02399901, -0.00269241, -0.00427578,  0.00347803,\n",
      "        -0.01162638, -0.00330356, -0.00491005,  0.00270546,  0.01034579,\n",
      "        -0.00706943,  0.00592995,  0.02649891,  0.00952865, -0.01625734,\n",
      "        -0.00520981,  0.00608283, -0.00633617,  0.0164276 , -0.00567177,\n",
      "         0.00281172,  0.01101176,  0.00519021, -0.00304196, -0.01016315,\n",
      "         0.00828768,  0.00916717,  0.02112458,  0.0048018 , -0.00623133,\n",
      "        -0.00211114, -0.01290154,  0.00835522,  0.01439239, -0.00322347,\n",
      "        -0.00651336,  0.01355802,  0.00610011, -0.0107618 , -0.00134245,\n",
      "        -0.00993497, -0.00797073, -0.00473341,  0.01103653]],\n",
      "      dtype=float32), array([[-1.35671524e-02, -1.71508938e-02,  2.88051181e-02,\n",
      "        -4.44392161e-03, -1.33167375e-02, -2.40398701e-02,\n",
      "         2.76318491e-02, -1.15328822e-02,  1.73795577e-02,\n",
      "        -2.75146309e-02, -2.39782054e-02, -4.00494691e-03,\n",
      "        -2.02362537e-02,  1.85200106e-02,  3.14489268e-02,\n",
      "        -4.22384543e-03,  3.70225199e-02, -1.58128608e-02,\n",
      "        -1.45941330e-02, -2.25824174e-02,  2.53473986e-02,\n",
      "        -4.05513542e-03,  1.69559252e-02, -7.34494580e-03,\n",
      "         3.36809829e-03,  2.75738202e-02,  1.80056307e-03,\n",
      "         3.02062742e-03, -2.64395382e-02,  2.04812139e-02,\n",
      "        -3.98714049e-03, -2.43132245e-02,  1.17342751e-02,\n",
      "        -1.57953415e-03, -1.55467854e-03,  4.35197493e-03,\n",
      "         8.50206334e-03, -1.14948582e-02,  1.17946621e-02,\n",
      "         1.25715397e-02, -6.34764414e-03,  2.46557351e-02,\n",
      "        -1.56730157e-03, -6.90125441e-03, -3.90992034e-03,\n",
      "         1.24586327e-02, -7.65386721e-05,  1.23531176e-02,\n",
      "         4.38830117e-03,  1.09078048e-03, -1.20668113e-02,\n",
      "        -8.33542086e-03, -1.82291074e-03,  2.08799616e-02,\n",
      "        -7.59530673e-03, -1.26648182e-02,  9.59876925e-03,\n",
      "        -9.17378173e-04, -2.28149307e-04,  5.95583813e-03,\n",
      "         8.26355629e-03, -5.01500070e-03,  1.75637249e-02,\n",
      "         1.44746322e-02]], dtype=float32), array([[-0.01078334, -0.01630737,  0.02797763, -0.00336495, -0.01090707,\n",
      "        -0.02515487,  0.02766134, -0.01381304,  0.01710702, -0.02640632,\n",
      "        -0.0233629 , -0.00292518, -0.0191737 ,  0.01790585,  0.02886255,\n",
      "        -0.00611169,  0.03289169, -0.01349095, -0.01487449, -0.02337017,\n",
      "         0.02534136, -0.00255498,  0.01700653, -0.00702298,  0.00211998,\n",
      "         0.02680595,  0.0008493 ,  0.00223542, -0.02161465,  0.02137545,\n",
      "        -0.0032118 , -0.02374905,  0.01421249,  0.00284617,  0.00553894,\n",
      "        -0.00778293, -0.00454393, -0.00229641,  0.0053709 ,  0.00148447,\n",
      "        -0.00575233,  0.00627638,  0.00236789, -0.00053764, -0.00858179,\n",
      "         0.00280549,  0.00697564, -0.0032546 ,  0.00166743,  0.0016205 ,\n",
      "        -0.0065305 ,  0.00274602, -0.01002082,  0.00664434,  0.0036468 ,\n",
      "        -0.00441237, -0.00139709,  0.00259375, -0.01472466,  0.00917792,\n",
      "        -0.00579543, -0.0083159 ,  0.00594948,  0.01332669]],\n",
      "      dtype=float32), array([[-9.29962005e-03, -1.40536698e-02,  2.68905926e-02,\n",
      "        -1.73024461e-03, -1.10858986e-02, -2.40727570e-02,\n",
      "         2.61927582e-02, -1.39328083e-02,  1.67446733e-02,\n",
      "        -2.16868073e-02, -2.15372257e-02,  1.00411307e-04,\n",
      "        -1.66733842e-02,  1.96521357e-02,  2.82820705e-02,\n",
      "        -6.77045062e-03,  2.89581940e-02, -1.37278233e-02,\n",
      "        -1.46393683e-02, -2.56598834e-02,  2.65422631e-02,\n",
      "         3.54171389e-05,  1.68718453e-02, -5.89979580e-03,\n",
      "         1.66837533e-04,  2.82666590e-02,  1.32319203e-03,\n",
      "         3.14023183e-03, -2.06443612e-02,  2.22180020e-02,\n",
      "        -3.71643645e-03, -2.02950761e-02,  1.50336069e-03,\n",
      "        -1.52481226e-02,  2.69146713e-05, -4.87951143e-03,\n",
      "        -6.36938680e-03,  9.72010102e-03,  2.13676468e-02,\n",
      "         1.60746574e-02, -1.12060979e-02,  3.35993022e-02,\n",
      "         7.89071433e-04, -1.10404715e-02,  4.01321566e-03,\n",
      "         8.33784789e-03,  5.29572414e-03,  2.41541397e-03,\n",
      "         8.80540349e-03, -6.19610131e-04, -1.24734845e-02,\n",
      "        -3.56937200e-03,  1.28210336e-03,  1.99186001e-02,\n",
      "        -1.52203478e-02, -1.64074004e-02, -6.77140942e-03,\n",
      "        -2.01598890e-02,  8.19935463e-04, -5.94144315e-03,\n",
      "         1.81469414e-03,  9.82143544e-03,  1.87426396e-02,\n",
      "        -5.86642942e-04]], dtype=float32), array([[-0.00483991,  0.02707596, -0.00535996, -0.01245845,  0.0021523 ,\n",
      "        -0.01276314, -0.00561677,  0.00806835, -0.00528189,  0.0132658 ,\n",
      "         0.00804854,  0.0139221 , -0.00931999,  0.00725843,  0.00184874,\n",
      "        -0.00890393,  0.0034226 , -0.00273854, -0.03876424,  0.01440076,\n",
      "        -0.00570397,  0.02399901, -0.00269241, -0.00427578,  0.00347803,\n",
      "        -0.01162638, -0.00330356, -0.00491005,  0.00270546,  0.01034579,\n",
      "        -0.00706943,  0.00592995,  0.02649891,  0.00952865, -0.01625734,\n",
      "        -0.00520981,  0.00608283, -0.00633617,  0.0164276 , -0.00567177,\n",
      "         0.00281172,  0.01101176,  0.00519021, -0.00304196, -0.01016315,\n",
      "         0.00828768,  0.00916717,  0.02112458,  0.0048018 , -0.00623133,\n",
      "        -0.00211114, -0.01290154,  0.00835522,  0.01439239, -0.00322347,\n",
      "        -0.00651336,  0.01355802,  0.00610011, -0.0107618 , -0.00134245,\n",
      "        -0.00993497, -0.00797073, -0.00473341,  0.01103653]],\n",
      "      dtype=float32), array([[-1.35671524e-02, -1.71508938e-02,  2.88051181e-02,\n",
      "        -4.44392161e-03, -1.33167375e-02, -2.40398701e-02,\n",
      "         2.76318491e-02, -1.15328822e-02,  1.73795577e-02,\n",
      "        -2.75146309e-02, -2.39782054e-02, -4.00494691e-03,\n",
      "        -2.02362537e-02,  1.85200106e-02,  3.14489268e-02,\n",
      "        -4.22384543e-03,  3.70225199e-02, -1.58128608e-02,\n",
      "        -1.45941330e-02, -2.25824174e-02,  2.53473986e-02,\n",
      "        -4.05513542e-03,  1.69559252e-02, -7.34494580e-03,\n",
      "         3.36809829e-03,  2.75738202e-02,  1.80056307e-03,\n",
      "         3.02062742e-03, -2.64395382e-02,  2.04812139e-02,\n",
      "        -3.98714049e-03, -2.43132245e-02,  1.17342751e-02,\n",
      "        -1.57953415e-03, -1.55467854e-03,  4.35197493e-03,\n",
      "         8.50206334e-03, -1.14948582e-02,  1.17946621e-02,\n",
      "         1.25715397e-02, -6.34764414e-03,  2.46557351e-02,\n",
      "        -1.56730157e-03, -6.90125441e-03, -3.90992034e-03,\n",
      "         1.24586327e-02, -7.65386721e-05,  1.23531176e-02,\n",
      "         4.38830117e-03,  1.09078048e-03, -1.20668113e-02,\n",
      "        -8.33542086e-03, -1.82291074e-03,  2.08799616e-02,\n",
      "        -7.59530673e-03, -1.26648182e-02,  9.59876925e-03,\n",
      "        -9.17378173e-04, -2.28149307e-04,  5.95583813e-03,\n",
      "         8.26355629e-03, -5.01500070e-03,  1.75637249e-02,\n",
      "         1.44746322e-02]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "for s1, s2 in new_samples:\n",
    "    new_input = tokenizer.texts_to_sequences([s1 + ' ' + s2 + ' ' + s1])\n",
    "    new_input = pad_sequences(new_input, maxlen=max_length, padding='post')\n",
    "    new_encoded = encoder.predict(new_input)\n",
    "    new_encoded_samples.append(new_encoded)\n",
    "\n",
    "# Now you can use new_encoded_samples for further analysis or predictions\n",
    "print(\"Encoded data for new samples:\")\n",
    "print(new_encoded_samples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
